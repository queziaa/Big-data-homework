{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个特征的增益为0.108\n",
      "第1个特征的增益为0.143\n",
      "第2个特征的增益为0.141\n",
      "第3个特征的增益为0.381\n",
      "第4个特征的增益为0.289\n",
      "第5个特征的增益为0.006\n",
      "训练集的熵为:0.997503\n",
      "最优特征索引值:3\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "def createDataSet():\n",
    "    data = {\n",
    "        '色泽': ['0', '1', '1', '0', '2', '0', '1', '1', '1', '0', '2', '2', '0', '2', '1', '2', '0'],\n",
    "        '根蒂': ['0', '0', '0', '0', '0', '1', '1', '1', '1', '2', '2', '0', '1', '1', '1', '0', '0'],\n",
    "        '敲声': ['0', '1', '0', '1', '0', '0', '0', '0', '1', '2', '2', '0', '0', '1', '0', '0', '1'],\n",
    "        '纹理': ['0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '2', '2', '1', '1', '0', '2', '1'],\n",
    "        '脐部': ['0', '0', '0', '0', '0', '1', '1', '1', '1', '2', '2', '2', '0', '0', '1', '2', '1'],\n",
    "        '触感': ['0', '0', '0', '0', '0', '1', '1', '0', '0', '1', '0', '1', '0', '0', '1', '0', '0'],\n",
    "        '好瓜': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    }\n",
    "\n",
    "    la = ['色泽', '根蒂', '敲声', '纹理', '脐部', '触感']\n",
    "    \n",
    "    dataSet = []\n",
    "    for i in range(len(data['好瓜'])):\n",
    "        temp = []\n",
    "        for j in la:\n",
    "            temp.append(data[j][i])\n",
    "        temp.append(data['好瓜'][i])\n",
    "        dataSet.append(temp)\n",
    "    return dataSet, la\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "函数说明:计算给定数据集的经验熵(香农熵)\n",
    "Parameters:\n",
    "    dataSet - 数据集\n",
    "Returns:\n",
    "    shannonEnt - 经验熵(香农熵)\n",
    "\"\"\"\n",
    "def calcShannonEnt(dataSet):\n",
    "    numEntires = len(dataSet)                        #返回数据集的行数\n",
    "    labelCounts = {}                                 #保存每个标签(Label)出现次数的字典\n",
    "    for featVec in dataSet:                          #对每组特征向量进行统计\n",
    "        currentLabel = featVec[-1]                   #提取标签(Label)信息\n",
    "        if currentLabel not in labelCounts.keys():   #如果标签(Label)没有放入统计次数的字典,添加进去\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1               #Label计数\n",
    "    shannonEnt = 0.0                                 #经验熵(香农熵)\n",
    "    for key in labelCounts:                          #计算香农熵\n",
    "        prob = float(labelCounts[key]) / numEntires  #选择该标签(Label)的概率\n",
    "        shannonEnt -= prob * log(prob, 2)            #利用公式计算\n",
    "    return shannonEnt                                #返回经验熵(香农熵)\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "函数说明:按照给定特征划分数据集\n",
    "Parameters:\n",
    "    dataSet - 待划分的数据集\n",
    "    axis - 划分数据集的特征\n",
    "    value - 需要返回的特征的值\n",
    "\"\"\"\n",
    "def splitDataSet(dataSet, axis, value):\n",
    "    retDataSet = []                                     #创建返回的数据集列表\n",
    "    for featVec in dataSet:                             #遍历数据集\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]             #去掉axis特征\n",
    "            reducedFeatVec.extend(featVec[axis+1:])     #将符合条件的添加到返回的数据集\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet                                   #返回划分后的数据集\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "函数说明:选择最优特征\n",
    "Parameters:\n",
    "    dataSet - 数据集\n",
    "Returns:\n",
    "    bestFeature - 信息增益最大的(最优)特征的索引值\n",
    "\"\"\"\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1                     #特征数量\n",
    "    baseEntropy = calcShannonEnt(dataSet)                 #计算数据集的香农熵\n",
    "    bestInfoGain = 0.0                                    #信息增益\n",
    "    bestFeature = -1                                      #最优特征的索引值\n",
    "    for i in range(numFeatures):                          #遍历所有特征\n",
    "        #获取dataSet的第i个所有特征\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList)                         #创建set集合{},元素不可重复\n",
    "        newEntropy = 0.0                                   #经验条件熵\n",
    "        for value in uniqueVals:                           #计算信息增益\n",
    "            subDataSet = splitDataSet(dataSet, i, value)           #subDataSet划分后的子集\n",
    "            prob = len(subDataSet) / float(len(dataSet))           #计算子集的概率\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)        #根据公式计算经验条件熵\n",
    "        infoGain = baseEntropy - newEntropy                        #信息增益\n",
    "        print(\"第%d个特征的增益为%.3f\" % (i, infoGain))             #打印每个特征的信息增益\n",
    "        if (infoGain > bestInfoGain):                              #计算信息增益\n",
    "            bestInfoGain = infoGain                                #更新信息增益，找到最大的信息增益\n",
    "            bestFeature = i                                        #记录信息增益最大的特征的索引值\n",
    "    return bestFeature                                             #返回信息增益最大的特征的索引值\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    dataSet, features = createDataSet()\n",
    "    entropy=calcShannonEnt(dataSet)\n",
    "    bestfeature=chooseBestFeatureToSplit(dataSet)\n",
    "    print(\"训练集的熵为:%f\"%(entropy))\n",
    "    print(\"最优特征索引值:\" + str(bestfeature))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weibodatacleaning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
