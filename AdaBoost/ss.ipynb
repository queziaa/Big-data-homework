{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 93.33%\n",
      "Testing Accuracy: 90.00%\n",
      "Training Accuracy with 1 classifiers: 47.78%\n",
      "Testing Accuracy with 1 classifiers: 45.00%\n",
      "\n",
      "Training Accuracy with 2 classifiers: 32.22%\n",
      "Testing Accuracy with 2 classifiers: 25.00%\n",
      "\n",
      "Training Accuracy with 3 classifiers: 3.33%\n",
      "Testing Accuracy with 3 classifiers: 6.67%\n",
      "\n",
      "Training Accuracy with 4 classifiers: 3.33%\n",
      "Testing Accuracy with 4 classifiers: 6.67%\n",
      "\n",
      "Training Accuracy with 5 classifiers: 11.11%\n",
      "Testing Accuracy with 5 classifiers: 11.67%\n",
      "\n",
      "Training Accuracy with 6 classifiers: 67.78%\n",
      "Testing Accuracy with 6 classifiers: 65.00%\n",
      "\n",
      "Training Accuracy with 7 classifiers: 75.56%\n",
      "Testing Accuracy with 7 classifiers: 71.67%\n",
      "\n",
      "Training Accuracy with 8 classifiers: 67.78%\n",
      "Testing Accuracy with 8 classifiers: 65.00%\n",
      "\n",
      "Training Accuracy with 9 classifiers: 51.11%\n",
      "Testing Accuracy with 9 classifiers: 51.67%\n",
      "\n",
      "Training Accuracy with 10 classifiers: 67.78%\n",
      "Testing Accuracy with 10 classifiers: 66.67%\n",
      "\n",
      "Training Accuracy with 11 classifiers: 53.33%\n",
      "Testing Accuracy with 11 classifiers: 60.00%\n",
      "\n",
      "Training Accuracy with 12 classifiers: 67.78%\n",
      "Testing Accuracy with 12 classifiers: 70.00%\n",
      "\n",
      "Training Accuracy with 13 classifiers: 61.11%\n",
      "Testing Accuracy with 13 classifiers: 66.67%\n",
      "\n",
      "Training Accuracy with 14 classifiers: 84.44%\n",
      "Testing Accuracy with 14 classifiers: 80.00%\n",
      "\n",
      "Training Accuracy with 15 classifiers: 75.56%\n",
      "Testing Accuracy with 15 classifiers: 75.00%\n",
      "\n",
      "Training Accuracy with 16 classifiers: 68.89%\n",
      "Testing Accuracy with 16 classifiers: 75.00%\n",
      "\n",
      "Training Accuracy with 17 classifiers: 77.78%\n",
      "Testing Accuracy with 17 classifiers: 80.00%\n",
      "\n",
      "Training Accuracy with 18 classifiers: 77.78%\n",
      "Testing Accuracy with 18 classifiers: 80.00%\n",
      "\n",
      "Training Accuracy with 19 classifiers: 78.89%\n",
      "Testing Accuracy with 19 classifiers: 78.33%\n",
      "\n",
      "Training Accuracy with 20 classifiers: 81.11%\n",
      "Testing Accuracy with 20 classifiers: 83.33%\n",
      "\n",
      "Training Accuracy with 21 classifiers: 86.67%\n",
      "Testing Accuracy with 21 classifiers: 83.33%\n",
      "\n",
      "Training Accuracy with 22 classifiers: 94.44%\n",
      "Testing Accuracy with 22 classifiers: 93.33%\n",
      "\n",
      "Training Accuracy with 23 classifiers: 93.33%\n",
      "Testing Accuracy with 23 classifiers: 95.00%\n",
      "\n",
      "Training Accuracy with 24 classifiers: 93.33%\n",
      "Testing Accuracy with 24 classifiers: 93.33%\n",
      "\n",
      "Training Accuracy with 25 classifiers: 94.44%\n",
      "Testing Accuracy with 25 classifiers: 93.33%\n",
      "\n",
      "Training Accuracy with 26 classifiers: 93.33%\n",
      "Testing Accuracy with 26 classifiers: 91.67%\n",
      "\n",
      "Training Accuracy with 27 classifiers: 92.22%\n",
      "Testing Accuracy with 27 classifiers: 93.33%\n",
      "\n",
      "Training Accuracy with 28 classifiers: 93.33%\n",
      "Testing Accuracy with 28 classifiers: 93.33%\n",
      "\n",
      "Training Accuracy with 29 classifiers: 95.56%\n",
      "Testing Accuracy with 29 classifiers: 95.00%\n",
      "\n",
      "Training Accuracy with 30 classifiers: 93.33%\n",
      "Testing Accuracy with 30 classifiers: 90.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def stump(X, y, weights):\n",
    "    m, n = X.shape\n",
    "    best_stump = {}\n",
    "    min_error = float('inf')\n",
    "    \n",
    "    for j in range(n):  # 对每个特征\n",
    "        feature_values = np.unique(X[:, j])\n",
    "        for threshold in feature_values:\n",
    "            for inequality in [\"lt\", \"gt\"]:  # \"lt\" - less than, \"gt\" - greater than\n",
    "                predicted_labels = np.where(X[:, j] < threshold, -1, 1)\n",
    "                if inequality == \"gt\":\n",
    "                    predicted_labels = -predicted_labels\n",
    "                errors = weights[y != predicted_labels]\n",
    "                weighted_error = np.sum(errors)\n",
    "                \n",
    "                if weighted_error < min_error:\n",
    "                    min_error = weighted_error\n",
    "                    best_stump['feature'] = j\n",
    "                    best_stump['threshold'] = threshold\n",
    "                    best_stump['ineq'] = inequality\n",
    "                    best_stump['label'] = predicted_labels\n",
    "    \n",
    "    return best_stump, min_error\n",
    "\n",
    "def adaboost_train(X_t, y_t, M=10):\n",
    "    weights = np.full(len(X_t), 1/len(X_t))\n",
    "    alpha = []\n",
    "    classifiers = []\n",
    "\n",
    "    for _ in range(M):\n",
    "        # 每次随机删除一部分数据集合 以弱化基础分类器性能\n",
    "        # idx = np.random.choice(len(X_t), len(X_t), replace=True)\n",
    "        X = X_t\n",
    "        # y = y_t[idx]\n",
    "\n",
    "        y = y_t.copy()\n",
    "        mask = np.random.rand(len(y)) < 0.45\n",
    "        y[mask] = -y[mask]\n",
    "    \n",
    "\n",
    "        stump_info, error = stump(X, y, weights)\n",
    "        alpha_m = 0.5 * np.log((1 - error) / max(error, 1e-10))\n",
    "        alpha.append(alpha_m)\n",
    "        classifiers.append(stump_info)\n",
    "        \n",
    "        weights *= np.exp(-alpha_m * y * stump_info['label'])\n",
    "        weights /= np.sum(weights)\n",
    "    \n",
    "    return classifiers, alpha\n",
    "\n",
    "def adaboost_predict(X, classifiers, alpha):\n",
    "    predictions = np.zeros(len(X))\n",
    "    for alpha_m, classifier in zip(alpha, classifiers):\n",
    "        predictions += alpha_m * np.where(X[:, classifier['feature']] < classifier['threshold'], -1, 1) * (1 if classifier['ineq'] == 'lt' else -1)\n",
    "    return np.sign(predictions)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据集\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "y = np.where(y == 2, 1, -1)\n",
    "\n",
    "# 随机扰乱\n",
    "np.random.seed()\n",
    "# 分割数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=3)\n",
    "\n",
    "# 训练AdaBoost模型\n",
    "classifiers, alpha = adaboost_train(X_train, y_train, M=30)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "# 使用训练好的AdaBoost模型进行预测\n",
    "y_pred_train = adaboost_predict(X_train, classifiers, alpha)\n",
    "y_pred_test = adaboost_predict(X_test, classifiers, alpha)\n",
    "\n",
    "# 计算训练和测试精度\n",
    "train_accuracy = accuracy(y_train, y_pred_train)\n",
    "test_accuracy = accuracy(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# 分别测试每个classifiers 的 accuracy\n",
    "for i in range(len(classifiers)):\n",
    "    y_pred_train = adaboost_predict(X_train, classifiers[:i+1], alpha[:i+1])\n",
    "    y_pred_test = adaboost_predict(X_test, classifiers[:i+1], alpha[:i+1])\n",
    "    train_accuracy = accuracy(y_train, y_pred_train)\n",
    "    test_accuracy = accuracy(y_test, y_pred_test)\n",
    "    print(f\"Training Accuracy with {i+1} classifiers: {train_accuracy * 100:.2f}%\")\n",
    "    print(f\"Testing Accuracy with {i+1} classifiers: {test_accuracy * 100:.2f}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32177511971028633,\n",
       " 0.2234377884778482,\n",
       " 0.3181898635895324,\n",
       " 0.20001228068855928,\n",
       " 0.3287237173032285,\n",
       " 0.2871642630687942,\n",
       " 0.3254009238446642,\n",
       " 0.3010268115978227]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weibodatacleaning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
