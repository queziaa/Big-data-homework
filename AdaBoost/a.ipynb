{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 鸢尾花(iris)数据集\n",
    "# 数据集内包含 3 类共 150 条记录，每类各 50 个数据，\n",
    "# 每条记录都有 4 项特征：花萼长度、花萼宽度、花瓣长度、花瓣宽度，\n",
    "# 可以通过这4个特征预测鸢尾花卉属于（iris-setosa, iris-versicolour, iris-virginica）中的哪一品种。\n",
    "# 这里只取前100条记录，两项特征，两个类别。\n",
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, [0, 1, -1]])\n",
    "    for i in range(len(data)):\n",
    "        if data[i,-1] == 0:\n",
    "            data[i,-1] = -1\n",
    "    return data[:,:2], data[:,-1]\n",
    "\n",
    "# 辅助函数：抽取二维数据的第一维度和第二维度\n",
    "def extract12(x):\n",
    "    N=len(x)\n",
    "    x1,x2=[],[]\n",
    "    # 第一维度\n",
    "    for i in range(N):\n",
    "        x1.append(x[i][0])\n",
    "    # 第二维度\n",
    "    for i in range(N):\n",
    "        x2.append(x[i][1])\n",
    "    return x1,x2\n",
    "\n",
    "# 用一个类对象存储二维样本弱分类器的阈值\n",
    "# 下面会说明，二维样本弱分类器的阈值有维度、值本身、方向、对应的最小分类错误率四个属性\n",
    "# 最终得到的分类器本身是弱分类器的线性组合，因此需要再保存一个线性系数alpha\n",
    "class dv:\n",
    "    def __init__(self,dim=0,val=0.0,dire=1,err=1,alpha=0):\n",
    "        # 本类对象中的属性都是private的，故属性名用两个下划线开头\n",
    "        # 弱分类器的阈值所属于的维度\n",
    "        self.__dim=dim\n",
    "        # 阈值本身\n",
    "        self.__val=val\n",
    "        # 阈值方向，如果是1则大于阈值属于正类，是-1则相反\n",
    "        self.__dire=dire\n",
    "        # 用于储存在求弱分类器时当前得到的最小错误分类率\n",
    "        self.__err=err\n",
    "        # 该弱分类器的线性组合系数\n",
    "        self.__a=alpha\n",
    "    # 设置阈值所属于的维度\n",
    "    def setdim(self,dim):\n",
    "        self.__dim=dim\n",
    "    # 设置阈值本身\n",
    "    def setval(self,val):\n",
    "        self.__val=val\n",
    "    # 设置阈值的方向\n",
    "    def setdire(self,dire):\n",
    "        self.__dire=dire\n",
    "    # 更新（最小）错误分类率\n",
    "    def seterr(self,err):\n",
    "        self.__err=err\n",
    "    # 设置弱分类器的线性组合系数\n",
    "    def setalpha(self,a):\n",
    "        self.__a=a\n",
    "    # 获得阈值所属维度的接口函数\n",
    "    def getdim(self):\n",
    "        return self.__dim\n",
    "    # 获得阈值本身\n",
    "    def getval(self):\n",
    "        return self.__val\n",
    "    # 获得阈值的方向\n",
    "    def getdire(self):\n",
    "        return self.__dire\n",
    "    # 获得阈值的（最小）错误率\n",
    "    def geterr(self):\n",
    "        return self.__err\n",
    "    # 获得该弱分类器的线性组合系数\n",
    "    def getalpha(self):\n",
    "        return self.__a\n",
    "    # 用来print\n",
    "    def __str__(self):\n",
    "        return 'Threshold='+str(self.__val)+',Direction='+str(self.__dire)+',Dimension='+str(self.__dim)\n",
    "\n",
    "# 寻找基本分类器\n",
    "# 一维的弱分类器的求法：只需要遍历一系列阈值，找到能够让错误分类率最小的阈值就可以\n",
    "# 二维的弱分类器的求法比较复杂，先在第一个维度x1上寻找使得错误分类率最小的阈值\n",
    "# 但此时找到的阈值带有三个特性：一是该阈值是在第一个维度上的阈值，二是该阈值的方向（是大于阈值为正类还是相反），三是此时的最小错误分类率\n",
    "# 然后在第二个维度x2上寻找阈值，但如果在第二个维度上找到一个阈值使得此时的错误分类率小于之前得到的阈值，更新它\n",
    "# 因此最终得到的阈值有四个参数：维度、值、方向、此时的最小分类错误率\n",
    "# direction为1表示大于阈值是正类，为-1表示小于阈值是正类\n",
    "def find_weak_classifier(x,y,D):\n",
    "    # 初始化阈值为x1维度上的，值为0，方向1，最小分类错误率为1，线性组合系数为0，见类dv的定义\n",
    "    DV=dv()\n",
    "    # 抽取x1/x2维度\n",
    "    x1,x2=extract12(x)\n",
    "    # 先遍历x1,direction=1上的阈值\n",
    "    for v in range(0,100):\n",
    "        # 从0到10，间隔是0.1\n",
    "        v = float(v / 10)\n",
    "        # 测试当前维度、方向下的值为v的阈值的错误分类率\n",
    "        err_now=count_errate(x1,y,D,v,dire=1)\n",
    "        # 如果这个错误分类率不高于之前得到的最小错误分类率\n",
    "        if err_now<=DV.geterr():\n",
    "            # 更新最小错误分类率\n",
    "            DV.seterr(err_now)\n",
    "            # 更新阈值的值本身，此时还不用考虑是否要更新方向和维度\n",
    "            DV.setval(v)\n",
    "    # 遍历x1,direction=-1上的阈值\n",
    "    for v in range(0,100):\n",
    "        # 从0到10，间隔是0.1\n",
    "        v=float(v/10)\n",
    "        # 测试当前维度、方向下的值为v的阈值的错误分类率\n",
    "        err_now=count_errate(x1,y,D,v,dire=-1)\n",
    "        # 如果这个错误分类率不高于之前得到的最小错误分类率\n",
    "        if err_now<=DV.geterr():\n",
    "            # 更新最小错误分类率\n",
    "            DV.seterr(err_now)\n",
    "            # 更新阈值的值本身，此时还不用考虑是否要更新维度\n",
    "            DV.setval(v)\n",
    "            # 更新阈值的方向\n",
    "            DV.setdire(-1)\n",
    "    # 遍历x2,direction=1阈值\n",
    "    for v in range(0,100):\n",
    "        # v从0到10，间隔是0.1\n",
    "        v=float(v/10)\n",
    "        # 测试当前维度、方向下的值为v的阈值的错误分类率\n",
    "        err_now=count_errate(x2,y,D,v,dire=1)\n",
    "        # 如果这个错误分类率不高于之前得到的最小错误分类率\n",
    "        if err_now<=DV.geterr():\n",
    "            # 更新最小错误分类率\n",
    "            DV.seterr(err_now)\n",
    "            # 更新阈值的值本身\n",
    "            DV.setval(v)\n",
    "            # 更新阈值的方向\n",
    "            DV.setdire(1)\n",
    "            # 更新阈值的维度\n",
    "            DV.setdim(1)\n",
    "    # 遍历x2,direction=-1阈值\n",
    "    for v in range(0, 100):\n",
    "        # 从0到10，间隔是0.1\n",
    "        v = float(v / 10)\n",
    "        # 测试当前维度、方向下的值为v的阈值的错误分类率\n",
    "        err_now = count_errate(x2, y, D, v, dire=-1)\n",
    "        # 如果这个错误分类率不高于之前得到的最小错误分类率\n",
    "        if err_now <= DV.geterr():\n",
    "            # 更新最小错误分类率\n",
    "            DV.seterr(err_now)\n",
    "            # 更新阈值\n",
    "            DV.setval(v)\n",
    "            # 更新阈值方向\n",
    "            DV.setdire(-1)\n",
    "            # 更新阈值所在的维度\n",
    "            DV.setdim(1)\n",
    "    return DV\n",
    "\n",
    "# 方向为dire（1为大于阈值判为正类，-1则相反），阈值为v的一维基本分类器Gm(x)\n",
    "def Gm(x,v,dire):\n",
    "    # 方向为1\n",
    "    if dire==1:\n",
    "        # 则大于阈值为正类\n",
    "        if x>=v:\n",
    "            return 1\n",
    "        elif x<v:\n",
    "            return -1\n",
    "    # 方向为-1时，结果与方向为1时相反\n",
    "    elif dire==-1:\n",
    "        return (-1)*Gm(x,v,1)\n",
    "    # 不是1或者-1时\n",
    "    else:\n",
    "        # 抛出异常\n",
    "        raise ValueError('The direction should be either 1 or -1.')\n",
    "\n",
    "# 计算权值为D的数据集x-y在阈值为v、方向为dire（+1表示大于阈值为正类）的一维基本分类器上得到的分类错误率。\n",
    "def count_errate(x,y,D,v,dire):\n",
    "    # 用于累计错误\n",
    "    total_error=0\n",
    "    # 样本数量\n",
    "    N=len(x)\n",
    "    for i in range(N):\n",
    "        # 累计的错误率=（样本分类错误*该样本点的权值D[i]）的总和。\n",
    "        # (Gm(x[i],v,dire)!=y[i])表示样本分类错误。\n",
    "        total_error=total_error+(Gm(x[i],v,dire)!=y[i])*D[i]\n",
    "    return total_error\n",
    "\n",
    "# 对应统计学习方法157页的f(x),也就是基本分类器的线性组合\n",
    "def f(x,list_of_v):\n",
    "    y=0\n",
    "    for v in list_of_v:\n",
    "        # alpha（线性分类器的系数）*线性分类器的结果\n",
    "        y=y+v.getalpha()*Gm(x[v.getdim()],v.getval(),v.getdire())\n",
    "    return y\n",
    "\n",
    "# 对f(x)取符号函数就是最终分类器G(x)\n",
    "def G(x,list_of_v):\n",
    "    return np.sign(f(x,list_of_v))\n",
    "\n",
    "# 计算经过最终分类器（基本分类器的线性组合）的错误分类数\n",
    "def G_errate(x,y,N,list_of_v):\n",
    "    total_error = 0\n",
    "    for i in range(N):\n",
    "        total_error = total_error + (G(x[i], list_of_v) != y[i])\n",
    "    return total_error\n",
    "\n",
    "# Adaboost算法的循环部分（每一次循环找到一个基本分类器）\n",
    "# x是二维样本，y是样本的所属类，N是样本的数量，wm是每次循环需要更新的样本权值\n",
    "def Adaboost_Loop(x,y,N,wm):\n",
    "    # 根据每个样本的权值D=wm，找到基本分类器之一\n",
    "    v = find_weak_classifier(x, y, D=wm)\n",
    "    # 此时的带权值分类错误率\n",
    "    em = v.geterr()\n",
    "    # 计算该基本分类器的线性组合系数am\n",
    "    am = (1 / 2) * np.log((1 - em) / em)\n",
    "    # 设置该基本分类器的系数\n",
    "    v.setalpha(am)\n",
    "    # 储存新权值\n",
    "    w_new = np.zeros(N)\n",
    "    # 以下计算新权值，参考统计学习方法157页\n",
    "    e = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        e[i] = np.exp((-1) * am * y[i] * Gm(x[i][v.getdim()], v.getval(), v.getdire()))\n",
    "    Zm = 0\n",
    "    for i in range(N):\n",
    "        Zm = Zm + wm[i] * e[i]\n",
    "    for i in range(N):\n",
    "        w_new[i] = (wm[i] * e[i]) / Zm\n",
    "    # 新权值\n",
    "    wm = np.copy(w_new)\n",
    "    # 打印基本分类器的特性：阈值，方向，维度\n",
    "    print(v)\n",
    "    # 返回本次循环得到的基本分类器特性以及新权值\n",
    "    return v,wm\n",
    "\n",
    "# 画样本点以及最终分类器的分割线\n",
    "def draw(x,y,list_of_v,title):\n",
    "    # 样本点颜色\n",
    "    label = []\n",
    "    # 将鸢尾花数据转换成列表\n",
    "    xlist = x.tolist()\n",
    "    ylist = y.tolist()\n",
    "    # 由于样本点是二维的，提取其两个维度\n",
    "    ix1, ix2 = extract12(xlist)\n",
    "    # 设置样本点颜色，正类是红色，负类是蓝色\n",
    "    for i in range(len(xlist)):\n",
    "        if ylist[i] > 0:\n",
    "            label.append('r')\n",
    "        else:\n",
    "            label.append('b')\n",
    "    # 样本点散点\n",
    "    plt.scatter(ix1, ix2, color=label)\n",
    "    # 最终分类器分割线经过的点的坐标\n",
    "    contour_list = []\n",
    "    # 遍历包含所有样本点的最小矩形区域，根据“某一点被分类器判为正类，其邻居被判为负类”来判断某点是否在分割线上。\n",
    "    # 由于鸢尾花数据集的正类整体在右侧，负类在左侧，因此认为右边一点是正类的负类点在边界上\n",
    "    # 遍历的间隔是1/500,此时分割线是水平和垂直线\n",
    "    prec=500\n",
    "    x1_min, x1_max, x2_min, x2_max = int(prec * min(ix1)), int(prec * max(ix1)), int(prec * min(ix2)), int(prec * max(ix2))\n",
    "    for j in range(x2_min, x2_max + 1):\n",
    "        for i in range(x1_min, x1_max + 1):\n",
    "            temp = [i / prec, j / prec]\n",
    "            temp_next = [(i + 1) / prec, j / prec]\n",
    "            if f(temp, list_of_v) < 0 and f(temp_next, list_of_v) > 0:\n",
    "                contour_list.append(temp)\n",
    "    # 取出边界线上点坐标的两个维度\n",
    "    cx, cy = extract12(contour_list)\n",
    "    # 画折线图\n",
    "    plt.plot(cx, cy)\n",
    "    # 保存图像\n",
    "    plt.savefig(title)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 学习M个基本分类器，最终的分类器是这M个分类器的线性组合\n",
    "def train_with_M(x,y,M=20):\n",
    "    # 样本数量\n",
    "    N = len(x)\n",
    "    # 由M各基本分类器组成的列表。每个基本分类器对象包含其阈值的值/方向/所在维度，以及其在线性组合中的系数\n",
    "    list_of_v = []\n",
    "    # 初始化N个权重值分布\n",
    "    w_ini = np.ones(N) * 1 / N\n",
    "    wm = np.copy(w_ini)\n",
    "    # Adaboost主循环\n",
    "    for m in range(M):\n",
    "        v,wm=Adaboost_Loop(x,y,N,wm)\n",
    "        list_of_v.append(v)\n",
    "    # 计算使用最终分类器的错误分类数\n",
    "    total_error=G_errate(x,y,N,list_of_v)\n",
    "    return list_of_v,total_error\n",
    "\n",
    "# 遍历不同大小的M(M<=M_max),使得由M个分类器组成的最终的分类器能够使得错误分类数为0，求出满足这样条件的最小的M\n",
    "def mintrain(x,y,M_max=20):\n",
    "    # 样本数量\n",
    "    N=len(x)\n",
    "    M=0\n",
    "    # 由M各基本分类器组成的列表。每个基本分类器对象包含其阈值的值/方向/所在维度，以及其在线性组合中的系数\n",
    "    list_of_v=[]\n",
    "    for M in range(1, M_max):\n",
    "        # 测试每个M\n",
    "        # 初始化N个权重值分布\n",
    "        w_ini = np.ones(N) * 1 / N\n",
    "        wm = np.copy(w_ini)\n",
    "        # Adaboost主循环\n",
    "        for m in range(M):\n",
    "            v, wm = Adaboost_Loop(x, y, N, wm)\n",
    "            list_of_v.append(v)\n",
    "        # 计算此时得到的最终分类器在数据集上的错误分类数\n",
    "        total_error=G_errate(x,y,N,list_of_v)\n",
    "        # 如果错误分类数是0，则结束寻找M\n",
    "        if total_error == 0:\n",
    "            break\n",
    "        else:list_of_v = []\n",
    "    return list_of_v,M\n",
    "\n",
    "# 训练与画图\n",
    "def train_and_draw():\n",
    "    # 加载鸢尾花数据集\n",
    "    X,Y=create_data()\n",
    "    # irisx：N*2矩阵，N是样本点的数量，每个样本店是一个二维坐标里的点\n",
    "    # irisy：either +1 or -1\n",
    "    list_of_v,total_error=train_with_M(X,Y)\n",
    "    draw(X,Y,list_of_v,'20.jpg')\n",
    "\n",
    "# 主函数\n",
    "if __name__ == '__main__':\n",
    "    train_and_draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weibodatacleaning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
